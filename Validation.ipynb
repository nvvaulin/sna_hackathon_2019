{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to read the Parquet data\n",
    "import pyarrow.parquet as parquet\n",
    "# Used to train the baseline model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Used to calculate metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Used to perform aggregations\n",
    "import pandas\n",
    "\n",
    "# Where the downloaded data are\n",
    "input_path = './'\n",
    "# Where to store results\n",
    "output_path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 776 ms, sys: 124 ms, total: 900 ms\n",
      "Wall time: 783 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitriybugaichenko/anaconda/envs/python37/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read a single day to train model on as Pandas dataframe\n",
    "data = parquet.ParquetDataset(\n",
    "    # Path to the dataset\n",
    "    input_path + '/collabTrain/', \n",
    "    # Dates to read\n",
    "    filters = [('date','=','2018-02-07')])\\\n",
    "    .read(\n",
    "    # Columns to read\n",
    "    columns = [\n",
    "        'instanceId_userId',\n",
    "        'feedback',\n",
    "        'auditweights_svd_prelaunch', \n",
    "        'auditweights_ctr_high', \n",
    "        'auditweights_ctr_gender', \n",
    "        'auditweights_friendLikes'  \n",
    "    ]).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы используем немного другой АПИ, использующий дополнительные фишки паркета:\n",
    "* Читаем партиционированный датасет и фильтруем по указанной партиции.\n",
    "* Вычитываем только те колонки, которые планируем использовать - хранение в колоночном формате при этом существенно уменьшает объем, поднимаемый с диска (тогда как в рядных форматах, например, CSV, объем чтения с диска сократить не получилось бы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceId_userId</th>\n",
       "      <th>feedback</th>\n",
       "      <th>auditweights_svd_prelaunch</th>\n",
       "      <th>auditweights_ctr_high</th>\n",
       "      <th>auditweights_ctr_gender</th>\n",
       "      <th>auditweights_friendLikes</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>[Ignored]</td>\n",
       "      <td>0.626212</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384</td>\n",
       "      <td>[Ignored]</td>\n",
       "      <td>0.670187</td>\n",
       "      <td>0.026324</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384</td>\n",
       "      <td>[Ignored]</td>\n",
       "      <td>0.706036</td>\n",
       "      <td>0.190227</td>\n",
       "      <td>0.037928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384</td>\n",
       "      <td>[Ignored]</td>\n",
       "      <td>0.828584</td>\n",
       "      <td>0.092678</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>384</td>\n",
       "      <td>[Ignored]</td>\n",
       "      <td>0.869253</td>\n",
       "      <td>0.078030</td>\n",
       "      <td>0.014418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1017</td>\n",
       "      <td>[Liked]</td>\n",
       "      <td>0.657293</td>\n",
       "      <td>0.078131</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1371</td>\n",
       "      <td>[Clicked, Liked]</td>\n",
       "      <td>0.600730</td>\n",
       "      <td>0.103020</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1464</td>\n",
       "      <td>[Ignored]</td>\n",
       "      <td>0.830225</td>\n",
       "      <td>0.176874</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1917</td>\n",
       "      <td>[Ignored]</td>\n",
       "      <td>0.677664</td>\n",
       "      <td>0.044811</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2076</td>\n",
       "      <td>[Disliked]</td>\n",
       "      <td>0.351570</td>\n",
       "      <td>0.091754</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-02-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instanceId_userId          feedback  auditweights_svd_prelaunch  \\\n",
       "0                189         [Ignored]                    0.626212   \n",
       "1                384         [Ignored]                    0.670187   \n",
       "2                384         [Ignored]                    0.706036   \n",
       "3                384         [Ignored]                    0.828584   \n",
       "4                384         [Ignored]                    0.869253   \n",
       "5               1017           [Liked]                    0.657293   \n",
       "6               1371  [Clicked, Liked]                    0.600730   \n",
       "7               1464         [Ignored]                    0.830225   \n",
       "8               1917         [Ignored]                    0.677664   \n",
       "9               2076        [Disliked]                    0.351570   \n",
       "\n",
       "   auditweights_ctr_high  auditweights_ctr_gender  auditweights_friendLikes  \\\n",
       "0               0.018481                 0.000168                       NaN   \n",
       "1               0.026324                 0.002110                       NaN   \n",
       "2               0.190227                 0.037928                       NaN   \n",
       "3               0.092678                 0.012441                       NaN   \n",
       "4               0.078030                 0.014418                       NaN   \n",
       "5               0.078131                 0.011765                       NaN   \n",
       "6               0.103020                 0.017116                       NaN   \n",
       "7               0.176874                 0.006687                       1.0   \n",
       "8               0.044811                 0.002307                       NaN   \n",
       "9               0.091754                 0.015341                       1.0   \n",
       "\n",
       "         date  \n",
       "0  2018-02-07  \n",
       "1  2018-02-07  \n",
       "2  2018-02-07  \n",
       "3  2018-02-07  \n",
       "4  2018-02-07  \n",
       "5  2018-02-07  \n",
       "6  2018-02-07  \n",
       "7  2018-02-07  \n",
       "8  2018-02-07  \n",
       "9  2018-02-07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.13 s, sys: 22.4 ms, total: 2.15 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Construct the label (liked objects)\n",
    "y = data['feedback'].apply(lambda x: 1.0 if(\"Liked\" in x) else 0.0).values\n",
    "\n",
    "# Extract the most interesting features\n",
    "X = data[[\n",
    "        'auditweights_svd_prelaunch', \n",
    "        'auditweights_ctr_high', \n",
    "        'auditweights_ctr_gender', \n",
    "        'auditweights_friendLikes']].fillna(0.0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.38 s, sys: 623 ms, total: 3 s\n",
      "Wall time: 868 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model and check the weights\n",
    "model = LogisticRegression(random_state=0, solver='lbfgs').fit(X, y)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глядя на то, что обучение модели заняло в 3-4 раза меньше времени, чем вычисление меток начинаем что-то подозревать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.42 s, sys: 468 ms, total: 2.89 s\n",
      "Wall time: 1.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitriybugaichenko/anaconda/envs/python37/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Pick one week for the test period\n",
    "test_dates = [[('date', '=', '2018-02-' + x)] for x in ['08','09','10','11','12','13','14']]\n",
    "\n",
    "# Read the test data for those days, only required columns\n",
    "test = parquet.ParquetDataset(input_path + '/collabTrain/', filters = test_dates)\\\n",
    "    .read(columns = [\n",
    "    'instanceId_userId',\n",
    "    'feedback',\n",
    "    'auditweights_svd_prelaunch', \n",
    "    'auditweights_ctr_high', \n",
    "    'auditweights_ctr_gender', \n",
    "    'auditweights_friendLikes'  \n",
    "    ]).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для теста мы возьмем неделю, непосредственно следующую за днем, на котором мы учились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 330 ms, sys: 161 ms, total: 490 ms\n",
      "Wall time: 235 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute inverted predictions (to sort by later)\n",
    "test[\"score\"] = model.predict_proba(test[[\n",
    "        'auditweights_svd_prelaunch', \n",
    "        'auditweights_ctr_high', \n",
    "        'auditweights_ctr_gender', \n",
    "        'auditweights_friendLikes']].fillna(0.0).values)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 281 ms, total: 13.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract labels and project\n",
    "test[\"label\"] = test['feedback'].apply(lambda x: 1.0 if(\"Liked\" in x) else 0.0)\n",
    "test = test[[\"instanceId_userId\", \"score\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращает на себя внимание очень длинное время работы параграфа, вызыванное в первую очередь большим количеством записей и выросшими в связи с этим накладными расходами интепретатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceId_userId</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252</td>\n",
       "      <td>0.128678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384</td>\n",
       "      <td>0.181584</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384</td>\n",
       "      <td>0.232244</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384</td>\n",
       "      <td>0.101478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>384</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>855</td>\n",
       "      <td>0.141115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1044</td>\n",
       "      <td>0.088706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1371</td>\n",
       "      <td>0.138298</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1584</td>\n",
       "      <td>0.152127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2319</td>\n",
       "      <td>0.127875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instanceId_userId     score  label\n",
       "0                252  0.128678    0.0\n",
       "1                384  0.181584    0.0\n",
       "2                384  0.232244    0.0\n",
       "3                384  0.101478    0.0\n",
       "4                384  0.358482    1.0\n",
       "5                855  0.141115    0.0\n",
       "6               1044  0.088706    0.0\n",
       "7               1371  0.138298    0.0\n",
       "8               1584  0.152127    0.0\n",
       "9               2319  0.127875    0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неправильный вариант валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 916 ms, sys: 179 ms, total: 1.1 s\n",
      "Wall time: 1.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7345059766307932"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "roc_auc_score(test.label, test.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу видно радикальное несоответствие результатам с сайта и это не оверфитинг. В данном варианте валидации есть существенная проблема - все объекты ранжируются единым списком, тогда как на практике (и в условиях конкурса) ранжирование делается индивидуально для пользователя. При смешении пользователь необоснованное преимущество получает та модель, которая тянеть наверх активнях юзеров, оставлющих много классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Правильный вариант валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(labels, scores):\n",
    "    # This is important! AUC can be computed only when both positive and negative examples are\n",
    "    # available\n",
    "    if len(labels) > sum(labels) > 0:\n",
    "        return roc_auc_score(labels, scores)\n",
    "\n",
    "    return float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 920 ms, total: 3min 22s\n",
      "Wall time: 3min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6663475856675231"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test.groupby(\"instanceId_userId\")\\\n",
    "    .apply(lambda y: auc(y.label.values, y.score.values))\\\n",
    "    .dropna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну а здесь прямо удручающее время работы, и опять из-за большого оверхеда на интерпретатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ускоренная грубой силой валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 366 ms, sys: 44.5 ms, total: 411 ms\n",
      "Wall time: 409 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Divide and conquer - split dataset into chunks by user ID\n",
    "max_user = max(test.instanceId_userId)\n",
    "batch_size = 1000000\n",
    "batches = [test[test.instanceId_userId.between(x, x + batch_size)] for x in range(0,max_user,batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a routine for AUC calculation\n",
    "def partitioned_auc(data):\n",
    "    return data.groupby(\"instanceId_userId\")\\\n",
    "        .apply(lambda y: auc(y.label.values, y.score.values))\\\n",
    "        .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94 ms, sys: 123 ms, total: 217 ms\n",
      "Wall time: 57.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Start processing of the batches in several threads\n",
    "with Pool(int(cpu_count() / 2)) as p:\n",
    "    ret_list = p.map(\n",
    "        partitioned_auc, \n",
    "        batches)\n",
    "\n",
    "pandas.concat(ret_list).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важный момент - этот подход не делает код более эффективным, он просто сжигает больше электричества активнее используя процессор. Кроме того не стоит жадничать и выделять все имеющиеся ядра - как правила в современных системах программы видят больше логических ядер чем реально есть в системе, при этом загрузка их всех единообразным процессом создаст неэффективную давку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заключительная ремарка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведенный код является упрощенной версией валидатора, запущенного на сайте и не содержит дополнительных защит от попыток манипуляций (например, отправки дубликатов или сокрытия части объектов). Если вы обнаружите дополнительные способы \"хакерской\" накрутки метрики, пожалуйста, сообщите организаторам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
